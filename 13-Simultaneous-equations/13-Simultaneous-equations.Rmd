---
title: "Simultaneous Equations"
subtitle: "EC420 MSU"
author: "Justin Kirkpatrick"
date: "Last updated `r format(Sys.Date(), '%B %d, %Y')`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    yolo: false
    css: [default, metropolis, metropolis-fonts, "EC420_S21.css"]
    nature: 
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false 

---
```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(knitr)
library(kableExtra)
opts_chunk$set(
   fig.path='figs/',
  out.width= '80%',
  fig.align = 'center',
  warning = F,
  message = F,
  error=F)
library(tidyverse)
require(cowplot)
require(ggpubr)
require(haven)
require(Statamarkdown)
require(plot3D)
require(stargazer)
require(quantmod)
require(wbstats)
require(lubridate)
require(scales)
require(broom)

options("getSymbols.warning4.0"=FALSE)
# require(see)
# 
# 

```

layout: true

<div class="msu-header"></div> 


---
class: MSU
# Last time

Endogeneity in regression
- $u$ correlated with an explanatory variable, $x_1$

Instrumental Variables
- A good instrument has:
  - Variation in $x_1$ not correlated with $u$
  - *Relevant first stage*, *independence assumption*, and *exclusion restriction*
- Allowed us to *identify* the coefficient of interest $\beta_1 x_1$
  
Estimated with 2SLS
- There are other methods (GMM)
  - But we won't cover them here
  
---
class: MSU
# Today

- More endogeneity!

- *Simultaneous* equations

- Structural equations
  - Reduced form equations

- When can we identify?

- How do we estimate
  - 2SLS
  
- In panel data
  - First difference
  - Fixed effects
  
  
---
class: MSU
# Recall

#### We think of the variables in our data as being either "endogenous" or "exogenous"
This tells us whether or not we should be worried about correlation with $u$.

### Exogenous
*Exogenous* means "determined outside the system".
- Things like *rainfall* in ag production and *winning the KIPP lottery* are *exogenous*
  - There is usually nothing *inside* the system that helps determine them.
--

  - Although...we could think of times that even rainfall is endogenous.
  - Any ideas about how *rainfall* could be endogenous?
  - What about a model that includes the selection of land for farming?
  - How could we fix this?

---
class: MSU
# Recall

### Endogenous
*Endogenous* means "determined within the system"
- Things like "education" in a wage equation and "moving my child to an (open-enrollment) charter school" are *endogenous*

We have had a few cases like this.
- First, when $x_1$ and $x_2$ are correlated
  - Not a problem when $x_1$ and $x_2$ are observable - we just include both in the regression or we "partial out".
- Next, when the variable of interest, $x_1$ is correlated with an unobservable in $u$
  - For this we, need an instrument

---
class: MSU
# Recall

### Endogeneous continuted...
For instance:
- When $(Y_{0i},Y_{1i})$ are different for some people, and *those* people choose the treatment based on that difference
  - Zuckerberg's $Y_{0i}$ (wages) for dropping out of Harvard was extraordinarily high. His choice was *endogenous*.
  - If we included him and people like him in a regression of $wages = \beta_0 + \beta_1 1(drop-out-of-college) + u$, we'd most certainly get the result that everyone should drop out of college!
--

- Any idea of how to solve the endogeneity problem in the Zuckerberg example?


---
class: MSU
# Simultaneity

In the "Zuckerberg-dropped-out-of-college" example, we have an omitted variable in the error (the *special, unique circumstance of having just invented facebook*) which is related to an explanatory variable, $1(drop-out-of-college)$
- The endogeneity is between an omitted variable and the variable of interest.
  - These are both on the right hand side
  - These are both explanatory variables

---
class: MSU
# Simultaneity 

## Simultaneity 
Simultaneity occurs when the *dependent variable*, the $y$, the left-hand-side, is determined jointly with one or more right-hand-side variables.
- Of course, it's always the case that the dependent variable $y$ is *determined* by one or more right hand side explanatory variables.
- $y = \beta_0 + \beta_1 x_1 + u$ shows this.
- But *simultaneity* is unique in that $x_1$ itself is *jointly determined* with $y$.


---
class: MSU
# Simultaneity

### An example of a county-level labor supply function
$$h_s = \alpha_1 w + \beta_1 z_1 + u_1$$
.pull-left[
- $h_s$ is the hours supplied each week by workers in the county

- $w$ is the wage
]

.pull-right[
- $z_1$ is anything that affects hours supplied

- $u_1$ is the error term for hours supplied
]

#### This equation stands on its own
- It has a causal interpretation (if $\alpha_1$ can be estimated without bias)
- It is derived from economic theory (higher wages cause people to substitute out of leisure and into labor)

$\Rightarrow$ **So we call this a structural equation**

---
class: MSU
# Simultaneity

$$h_s = \alpha_1 w + \beta_1 z_1 + u_1$$

### It suffers from simultaneity because:
- A county's $w$ will be determined, in part, by $h_s$, the supply.
- Wage is determined jointly by the interaction of $h_s$, $w$, and $h_d$, the hours demanded.
- Thus, **simultaneity**.

---
class: MSU
# Simultaneity

### The "link" between $h_s$ and $h_d$ is the equilibrium
- $h_s=h_d=h$. Since this happens in every county, we use $h_i$.
- We only observe this equilibrium, but we might want to know about the values of $\alpha_1$ and $\alpha_2$

### So we can take our two equations:
$$h_s = \alpha_1 w + \beta_1 z_1 + u_1$$
$$h_d = \alpha_2 w + \beta_2 z_2 + u_2$$


### And impose the equilibrium condition: for every $i$, $h_s = h_d = h_i$
$$h_i = \alpha_1 w_i + \beta_1 z_{1i} + u_{1i}$$

$$h_i = \alpha_2 w_i + \beta_2 z_{2i} + u_{2i}$$


---
class: MSU
# Simultaneity

### In this simultaneous system of equations:
$$h_i = \alpha_1 w_i + \beta_1 z_{1i} + u_{1i}$$

$$h_i = \alpha_2 w_i + \beta_2 z_{2i} + u_{2i}$$

$h_i$ and $w_i$ are the endogenous variables. Why?

### Because, given $z_{1i},z_{2i},u_{1i},u_{2i}$, then $h_i$ and $w_i$ are completely determined
- with a few assumptions about $\alpha_1$ and $\alpha_2$

### The dependent variable and one or more explanatory variables are jointly determined within the system.

---
class: MSU
# Simultaneity

### This happens often in economics
We have many parties interacting with each other, and equilibriums are the outcomes of those interactions.

Think of *marginal analysis* - how we think of a seller setting a price in a market. It's a lot of expectations about interactions.


---
class: MSU
# Simultaneity

### Back to the simultaneous system of equations:
$$h_i = \alpha_1 w_i + \beta_1 z_{1i} + u_{1i}$$

$$h_i = \alpha_2 w_i + \beta_2 z_{2i} + u_{2i}$$

### Note that the $z_{1i}$ and $z_{2i}$ are different variables, while $w_i$ is the same in both equations.
- $u_{1i}$ and $u_{2i}$ are different as well. And uncorrelated with each other.
- We refer to the $u_{1i}$ and $u_{21}$ as the *structural errors*.

---
class: MSU
# Simultaneity

### Example W 16.1
$$murdpc = \alpha_1 polpc + \beta_{10} + \beta_{11} incpc + u_1$$
$$polpc = \alpha_2 murdpc + \beta_{20} + other$$

.pull-left[
- $murdpc$ is murders per capita
- $incpc$ is income per capita, which shifts murder rates
- $\beta_{10}$ is the intercept for equation 1
]

.pull-right[
- $polpc$ is police per capita
- $\beta_{20}$ is the intercept for equation 2
]

### Is this simultaneous?
- Yes. Just as hours supplied, hours demanded, and wage are jointly determined, $murdpc$ and $polpc$ are jointly determined.
- The city chooses $polpc$ based, in part, on $murdpc$, while murderers choose $murdpc$ based, in part, on $polpc$.
- Even though we're interested in $\alpha_1$, we need to understand the second equation to avoid bias.

---
class: MSU
name: simeq
# Simultaneity

### Simultaneity bias
We can formally show the bias in simultaneous equations. Remember, bias occurs when an explanatory variable is correlated with $u$ (and thus $E[u|x]\neq 0$)

$$y_1 = \alpha_1 y_2 + \beta_1 z_1 + u_1$$

$$y_2 = \alpha_2 y_1 + \beta_2 z_2 + u_2$$
$y_1,y_2$ could be $murdpc$ and $polpc$.

### But estimating this first equation by OLS would result in a biased $\alpha_1$. So we can't do it. 
- Specifically, we are in trouble on the first if $y_2$ is correlated with $u_1$; 
- And if $y_1$ is correlated with $u_2$ for the second.
- Let's see why this is true...

---
class: MSU
# Simultaneity

### To see bias, substitute the first equation into the second
$$y_2 = \alpha_2 \underbrace{\color{red}{(\alpha_1 y_2 + \beta_1 z_1 + u_1)}}_{y_1} + \beta_2 z_2 + u_2$$
$$(1-\alpha_2 \alpha_1)y_2 = \alpha_2\beta_1 z_1 + \beta_2 z_2 + \underbrace{\alpha_2 u_1 + u_2}_{uh-oh}$$

---
class: MSU
# Simultaneity

Divide both sides by $(1-\alpha_2 \alpha_1)$:
$$y_2 = \frac{\alpha_2 \beta_1}{(1-\alpha_2 \alpha_1)} z_1 + \frac{\beta_2}{(1-\alpha_2 \alpha_1)}z_2 +  \underbrace{ \frac{\alpha_2}{(1-\alpha_2 \alpha_1)} u_1 +\frac{1}{(1-\alpha_2 \alpha_1)}u_2}_{v_2}$$

$$y_2 = \pi_{21} z_1 + \pi_{22} z_2 + v_2$$
### This is called the *reduced form* equation.
- We *can* estimate $\pi_{21}$ and $\pi_{22}$, but the coefficients lose their structural interpretation. 
- Our estimation of $\pi_{21}$ and $\pi_{22}$ is unbiased - $z$'s are exogenous, and $u_1$ itself is uncorrelated wtih $y_2$.


---
class: MSU
# Simultaneity

### Back to checking to see if we have bias in:
$$y_1 = \alpha_1 y_2 + \beta_1 z_1 + u_1$$
Remember, we are in trouble if $y_2$ is correlated with $u_1$, right?

Well, we know:
$$y_2 = \pi_{21} z_1 + \pi_{22} z_2 + v_2$$

and $v_2$, the reduced form error:

$$v_2 = \frac{\alpha_2}{(1-\alpha_2 \alpha_1)} u_1 +\frac{1}{(1-\alpha_2 \alpha_1)}u_2$$

Since $v_2$ has $u_1$ in it, and since $y_2$ has $v_2$ in it, then $y_2$ **is correlated with** $u_1$, and OLS of $y_1 = \alpha_1 y_2 + \beta_1 z_1 + u_1$ is biased.

### This is simultanaeity bias

---
class: MSU
# Simultaneity

### When can we identify $\alpha_1$ and $\alpha_2$?
- Our problem here is endogeneity, so we need an instrument. 
- Something that shifts $y_2$ but is not correlated with $u_1$ (exclusion restriction)
- Do we have something in $y_2$?

$$y_2 = \alpha_2 y_1 + \beta_2 z_2 + u_2$$
Yes. We have $z_2$, which is exogenous by definition.

It can shift $y_2$, and is not correlated with $u_1$. It does not shift $y_1$ except through $y_2$ because it is not in the equation for $y_1$.

---
class: MSU
# Simultaneity

### Similarly, we can use $z_1$ to shift $y_1$.
And both equations can be identified because we have *one exogenous shifter for each endogenous variable in each equation*.

### The Rank Condition
In a two-equation system, we can only identify an equation with an endogenous variable if the *other* equation has one or more exogenous variable that does not enter the first equation.
- The instrument must have a non-zero population coefficient

---
class: MSU
# Simultaneity

### Our two equation system, again (with the problems in .red[red] and .blue[blue]:
$$y_1 = \alpha_1 \color{red}{y_2} + \beta_1 z_1 + \color{red}{u_1}$$

$$y_2 = \alpha_2 \color{blue}{y_1} + \beta_2 z_2 + \color{blue}{u_2}$$
---
class: MSU
# Simultaneity

### A visual example:
```{r Sim1, echo=F, include=T, out.width='55%'}
NN = 2000
a1 = 1.25
b1 = -3
a2 = -6
b2 = 1.25

pi21 = (a2*b1)/(1-a1*a2)
pi22 = (b2)/(1-a1*a2)
pi11 = (a1*b2)/(1-a1*a2)
pi12 = (b1)/(1-a1*a2)

df1 = tibble(z1 = sample(1:3, NN, replace=T),
             z2 = sample(2:5, NN, replace=T),
             u1 = rnorm(NN, 0, 3),
             u1cut = cut(u1, breaks= floor(min(u1)):ceiling(max(u1))),
             u2 = rnorm(NN, 0, 6),
             u2cut = cut(u2, breaks= floor(min(u2)):ceiling(max(u2))),
             y2 = pi21*z1 + pi22*z2 +  (a2*u1 + u2)/(1-a2*a1),  #u1*(a2/(1-a1*a2)) + u2/(1-a2*a1),
             y1 = pi11*z2 + pi12*z1 +  (a1*u2 + u1)/(1-a2*a1)) #u2*(a1/(1-a1*a2)) + u1/(1-a2*a1))

ggplot(data = df1, 
       aes(x = y2, y = y1)) + 
  geom_point() +
  geom_smooth(method='lm', formula=y~x) +
  ggtitle(paste0('True alpha_1=',a1))  + theme_bw() + theme(legend.position='none')

```

---
class: MSU
# Simultaneity

### Since the problem is that $y_2$ is correlated with $u_1$, what if we observed $u_1$?
```{r Sim2, echo=F, include=T, out.width='55%'}
ggplot(data = df1, 
       aes(x = y2, y = y1, col=as.factor(u1cut))) + 
  geom_point() +
  geom_abline(intercept=-3, slope=a1, lwd=2, lty=2) +
  ggtitle(paste0('True alpha_1=',a1)) + theme_bw() + theme(legend.position='none')

```
Of course, we can't control for $u_1$ since it is unobserved.

---
class: MSU
# Simultaneity

```{r Sim3, echo=F, include=T, out.width='55%'}
df1 = df1 %>%
  dplyr::mutate(y2hat = predict(lm(y2 ~ z1 + z2, df1)))

 ggplot(data = df1, 
       aes(x = y2, y = y1)) + 
  geom_point(size=1) + 
   geom_point(aes(x = y2hat, y=y1, col=as.factor(z2))) + 
  ggtitle(paste0('True alpha_1=',a1)) + theme_bw() 
```

The colored groupings are $\hat{y}_2$. Each grouping is a different $z_1$. As $z_2$ increases, $y_2$ increases within each grouping. As $y_2$ increases, in each grouping, $y_1$ *increases*.

---
class: MSU
# Simultaneity

### First stage
$$y_2 = \pi_{21} z_1 + \pi_{22} + v_2$$
```{r SimRes1, echo=F, include=T}
summary(lm(y2 ~ z1 + z2, df1))
```
---
class: MSU 
# Simultaneity

### Second stage
$$y_1 = \alpha_2 \hat{y}_2 + \beta_1 z_1 + u$$
```{r SimRes2, echo=F, include=T}
lmfin = lm(y1 ~ y2hat + z1, df1)
summary(lmfin)
```


---
class: MSU
# Simultaneity

### The second-stage coefficient
We get a pretty accurate estimate for $\alpha_1=`r round(coefficients(lmfin)[2], 2)`$ from the second-stage having used $z_2$ to instrument for $y_2$.

---
class: MSU
# Simultanaeity in panels

### In a panel data setting we'd have a *fixed effect* for each $i$:
$$y_{it1} = \alpha_1 y_{it2} + \mathbf{z_{it1} \beta_1} + a_{i1} + u_{it1}$$
$$y_{it2} = \alpha_2 y_{it1} + \mathbf{z_{it2} \beta_2} + a_{i2} + u_{it2}$$

$a_{i1}$ is unobserved and potentially correlated with $z_{it1}$. This presents interesting problems unique to panels.

---
class: MSU
# Simultaneity in panels


### First Differencing
One way of handling an unobserved fixed effect in panel data (different from what we've learned on fixed effects) is *first differencing*.

$$y_{it1}-y_{i(t-1)1} = \alpha_1 (y_{it2}-y_{i(t-1)2}) + \beta_1 (z_{it1}-z_{i(t-1)1}) + a_{i1} - a_{i1} + u_{it1}-u_{i(t-1)1}$$

Which can be written using the $\Delta$ notation:

$$\Delta y_{it1} = \alpha_1 \Delta y_{it2} + \beta_1 \Delta z_{it1} + \Delta u_{it1}$$
This removes the $a_{i1}$, and makes it clear that we need an instrument whose *change* is
- Exogenous
- Affects only $\Delta y_{it2}$ without affecting $\Delta y_{it1}$ (uncorrelated with $\Delta u_{it1}$).
- And *it has to vary within each* $i$

---
class: MSU
# Simultaneity in panels

### Using fixed effects
A similar result happens if we include the fixed effect. The fixed effect instruments for itself, and is included as an exogenous variable.

#### First stage
$$y_{it2} = \pi_{21} z_1 + \pi_{22} z_2 + \gamma^{1}_i + v_2$$
#### Second stage
$$y_{it1} = \alpha_1 \hat{y}_{it2} + \beta_1 z_1 + \gamma^{2}_i + u_1$$

$\gamma^1_i$ is the fixed effect for each $i$ in the first stage. 

$\gamma^2_i$ is the fixed effect for each $i$ in the second stage (not a squared term).

---
class: MSU
# Next week

### Difference in Differences
**Read MM Ch. 5**


```{r outputChromePrint, include=F, eval=F}

require(pagedown)
currentfile = gsub(pattern='\\.Rmd', '', basename(rstudioapi::getSourceEditorContext()$path))
inputpath = paste0('https://ajkirkpatrick.github.io/EC420MSU/',currentfile, '/', paste0(currentfile, '.html'))
browseURL(inputpath)
pagedown::chrome_print(input = inputpath,
                   output = file.path( paste0(currentfile, '.pdf')),
                   #wait = 3,
                   timeout = 300,
                   format = 'pdf')

```

